[["index.html", "BioCro Development Introduction Note about the types of documentation in BioCro Version Info", " BioCro Development 2023-11-03 Introduction The documentation in this short book is aimed at developers—at those who will be writing new modules or modifying existing ones; and most especially at those fixing bugs in or adding new features to the BioCro simulation framework, and those involved with the overall maintenance of the BioCro package. Note about the types of documentation in BioCro There several categories of documentation for BioCro: The top-level README.md is for general information about BioCro and is intended for potential users of the package. The files in man directory document the R functions and the data associated with the BioCro package and are intended for users of the package. The files in the vignettes directory are generally “longform” documentation, also intended for users of the package. There is the documentation generated by Doxygen, generally from comments in the C++ source files. This is of interest to developers, but general users may also be interested, particularly in the documentation of the various BioCro modules. Finally, there are various .md or .Rmd files scattered about the package that are referenced by the bookdown/_bookdown.yml configuration file, and that can be compiled into a book (this book, if you are reading this page in bookdown) using the bookdown package. This documentation is targeted at BioCro developers and maintainers. Version Info This document was generated from the version of BioCro specified as follows: Commit Hash: 8bef42a Date: Thu, 2 Nov 2023 21:15:19 -0500 Branch: "],["contributing-to-biocro.html", "1 Contributing to BioCro 1.1 Making Changes 1.2 Code style 1.3 Formatting Tools", " 1 Contributing to BioCro 1.1 Making Changes 1.1.1 Discuss first Check the list of GitHub issues for a discussion of the issue. If there is not one, create an issue with a description of the problem and your proposed solution. By making changes without discussing it with the group, you risk spending time working on a solution that others may not accept. The members of the group also have diverse backgrounds and likely can give valuable design insights. 1.2 Code style (Most of what is discussed here pertains specifically to code for the BioCro C++ library.) 1.2.1 Scientific considerations 1.2.1.1 Document sources and justification in the code Include citations to sources for equations and parameters used in the code. The citation should be sufficient to locate the article and relevant information within it. Include a table or figure reference if appropriate. Use Doxygen-style comment syntax for high-level documentation of functions and classes. (See the documentation of the solar_zenith_angle class in the Solar Zenith Angle module for a short example of a Doxygen-style comment.) Include reasoning and justification for the model, including assumptions that determine when use of the model is appropriate. These descriptions should be succinct. See the Ball-Berry model for an example. 1.2.1.2 Document units in the code After every physical quantity, include a comment with the units. The idea is that every quantity will roughly be read as if it were written in normal text: double yield = 10 // Mg / ha is something like “the yield was 10 Mg / ha”. Using dimensions instead of units is acceptable if the code is written with the expectation that coherent units are used. // In function signatures double ball_berry(double assimilation, // mol / m^2 / s double atmospheric_co2_concentration, // mol / mol double atmospheric_relative_humidity, // Pa / Pa double beta0, // mol / m^2 / s double beta1) // dimensionless from [mol / m^2 / s] / [mol / m^2 / s] // In assignments double leaf_temperature = air_temperature - delta_t; // K. // In return statements return assimilation_rate; // micromoles / m^2 / s. // In tables const std::map&lt;SoilType, soilText_str&gt; soil_parameters = { // d = dimensionless // d d d J kg^-1 d J s m^-3 d d d Mg m^-3 // silt clay sand air_entry b Ks satur fieldc wiltp bulk_density { SoilType::sand, { 0.05, 0.03, 0.92, -0.7, 1.7, 5.8e-3, 0.87, 0.09, 0.03, 1.60 } }, { SoilType::loamy_sand, { 0.12, 0.07, 0.81, -0.9, 2.1, 1.7e-3, 0.72, 0.13, 0.06, 1.55 } }, }; If you would like to include other details, include the units in the same way, and include details following the units so that the variables are still read like regular text. For example, write ✓ return gswmol * 1000; // mmol / m^2 / s. Convert from mol to mmol. not c++ ✗ return gswmol * 1000; // Converting from mol / m^2 / s to mmol / m^2 / s. Use SI conventions for units and dimensions, including capitalization. Specifically, use “degrees C”, not “C”, to indicate °C. Use full names when symbols are not available: micromoles / m^2, not umol / m^2 degrees C, not *C. Use dimensionless for dimensionless quantities, and include how the dimensions have canceled if that is informative. Use ^ to indicate exponentiation: m^2, not m2. Prefer an asterisk to indicate multiplication; but indicating multiplication by juxtaposing units with exactly one space between them is acceptable. Prefer exactly one space on each side of the asterisk: kg * m / s or kg m / s. Either a solidus (“/”) or negative exponent is acceptable to indicate division, but ensure that the solidus is used correctly if used multiple times. Prefer exactly one space on each side of the solidus. 1.2.1.3 Document parameters When adding models that require new parameters, document the parameters in the parameter table in src/parameters.h. Please keep the table well formatted. If you are working on a model with undocumented parameters, it would be nice if you added them to the table as you work through the issue. 1.2.2 General coding considerations Do not use C-style arrays. Use an appropriate data type from the standard library instead. Use cmath, not math.h, for common mathematical functions. Be careful with using-directives (e.g. using namespace std) in a global scope; do not use them in global scope in a header file. Try to make using-declarations (e.g. using std::string) as local as possible. Type aliases (e.g. using string_vector = std::vector&lt;std::string&gt;) are perfectly acceptable in the global scope of a header file. Strongly prefer the coherent set of SI units. Doing so reduces code complexity remarkably as no conversions are necessary. Yes, no one publishes values with these units, but do the conversion in one place, the manuscript, instead of dozens of times in the code, constantly having to look up units for variables, and then spending hours debugging silly, difficult-to-find errors. The coherent set of SI units consists of all the units without prefixes, except that kg is the coherent unit of mass, not g. Do not copy and paste code, changing only small parts. Choose a design that eliminates the duplication. Duplication is often the result of not separating control flow from data. Consider the following R code. if (!(&quot;lattice&quot; %in% installed.packages()[,&quot;Package&quot;])) { install.packages(&quot;lattice&quot;, repos=&quot;http://R-Forge.R-project.org&quot;, type=&quot;source&quot;) } if (!(&quot;BioCro&quot; %in% installed.packages()[,&quot;Package&quot;])) { devtools::install_github(&quot;ebimodeling/biocro&quot;) } if (!(&quot;boot&quot; %in% installed.packages()[,&quot;Package&quot;])) { devtools::install_url(&quot;http://cran.r-project.org/src/contrib/Archive/boot/boot_1.3-7.tar.gz&quot;) } The data and behavior can be separated. ```r required_packages = list( # package name # installation function # function arguments list(“lattice”, install.packages, list(“lattice”, repos=“http://R-Forge.R-project.org”, type=“source”)), list(“BioCro”, devtools::install_github, list(“ebimodeling/biocro”)), list(“boot”, devtools::install_url, list(“http://cran.r-project.org/src/contrib/Archive/boot/boot_1.3-7.tar.gz”)) ) install_packages_if_missing = function(package_table) { installed_packages = installed.packages()[,“Package”] for (row in package_table) { if (!(row[[1]] %in% installed_packages)) { do.call(row[[2]], row[[3]]) } } } install_packages_if_missing(required_packages) ``` In the first example, the behavior is spread throughout all of the code, and there is not an obvious indication of what is being done. Once one understands what is being done, one must still read all of the code to be sure some different behavior is not hidden somewhere. In the second example, it is clear that the same task is performed repeatedly because control flow is in a single place, and the place has a meaningful name: install_packages_if_missing. For a long list, this is succinct, and easier to understand and maintain. If one wanted, one could devise a way to use the meaningful names of the columns of the required_packages table within the function. Make an effort to write unit tests. (See the document “An Introduction to BioCro for Those Who Want to Add Models” for information about writing unit tests—specifically, writing unit tests for new modules.) Do not mix sweeping formatting changes with behavior changes. Large formatting changes should be committed separately, and the commit comment should indicate that only formatting was changed. The C++ guidelines have useful advice about aspects of coding and design. 1.2.3 Formatting code (Again, except in a few instances, this pertains specifically to C++ code.) The most important aspect of formatting is that the code is easy to understand. Below are unenforced preferences. Prefer underscores_in_identifiers not CamelCaseInIdentifiers and, in R, not dots.in.identifiers. Prefer lowercase-only identifiers. An exception may be made for commonly-recognized names used in a small scope, for example, c++ I = V / R; F = m * a; E = m * (c * c); Avoid unnecessary parentheses. For example, use “a * b / c” instead of “(a * b) / c” or “a * (b / c)”. But in cases where the order of operations affects the result, parentheses may be used to erase any doubt in the mind of the reader (or the programmer!) as to what that order is. Thus, writing (a / b) * c instead of (the equivalent) a / b * c is acceptable. Parentheses may also be used to group portions of a formula that are commonly considered as a subunit, where they provide some semantic value (see the previous bullet point). Consider naming parts of a complicated expression in order to break it down into simpler ones. For example, c++ x = (-b + sqrt(b * b - 4 * a * c)) / (2 * a); may be rewritten in three lines as c++ num = -b + sqrt(b * b - 4 * a * c); denom = 2 * a; x = num / denom; Note that in C++, unlike in R, return statements do not require parentheses around the returned expression. Restrict the line length of paragraph-like comments to 80 characters, excepting a compelling reason to do otherwise. Lines in sections that are not paragraph-like could be somewhat longer if it facilitates presenting material in a more readable format. In the following snippet from the module library documentation, for example, we have allowed slighly-longer lines in order to be able to maintain one line per interval: /* * However, this definition is flexible. For example, for our soybean model * (soybean_development_rate_calculator.h) we define the intervals as follows: * -1 &lt;= DVI &lt; 0 : Sowing to Emergence * 0 &lt;= DVI &lt; 1 : Emergence to R1 (Flowering) is broken into three stages. * 0 &lt;= DVI &lt; 0.333 : Emergence to V0 (Cotyledon stage) * 0.333 &lt;= DVI &lt; 0.667 : V0 (Cotyledon stage) to R0 (End of Floral Induction) * 0.667 &lt;= DVI &lt; 1 : R0 (End of Floral Induction) to R1 (Flowering) * 1 &lt;= DVI &lt; 2 : R1 (Flowering) to R7 (Maturity) */ As for the code lines themselves, we point to the following advice from the Linux kernel project:1 The preferred limit on the length of a single line is 80 columns. Statements longer than 80 columns should be broken into sensible chunks, unless exceeding 80 columns significantly increases readability and does not hide information. Do not include trailing whitespace, i.e., whitespace characters preceding newline characters. Each file should end with a newline character (i.e. a terminal endline). Use spaces rather than tab characters. In general, formatting preferences should follow something similar to the Google C++ style guide, except in cases where the code has been formatted in a more readable way, such as when aligning parts in a table. The C++ guidelines offer some advice about formatting conventions that are informative, particularly regarding the use of code comments, but that are not enforced here. For tools to help with formatting code, see the section 1.3. 1.2.4 R-specific coding advice Prefer to use the double-bracket operator (list[['element']]) rather than the dollar-sign operator (list$element) when accessing the elements of a list. The $ operator uses partial matching, whereas [[, by default, does not. (However, it can be specified: list[['element', exact = FALSE]].) Avoiding partial matching by using [[ gives us more confidence that errors won’t occur. While there is no inherent performance difference between a for loop and an apply-type function such as apply or lapply (the apply functions actually use for loops in their source code), it is nevertheless possible to write a “bad” for loop that runs slowly. Common culprits include a failure to pre-allocate memory or a poor choice in assignment method. If a for loop seems to run slowly, consider replacing it with an apply-type function or tweaking the assignment method (e.g. replacing append with [). Many guides for optimizing loop performance are available online, such as Strategies to Speedup R Code and Why loops are slow in R. 1 The Linux kernel project recently changed the default length for code lines from 80 to 100 characters with the following commit comment: Yes, staying withing 80 columns is certainly still preferred. But it’s not the hard limit that the checkpatch warnings imply, and other concerns can most certainly dominate. Increase the default limit to 100 characters. Not because 100 characters is some hard limit either, but that’s certainly a “what are you doing” kind of value and less likely to be about the occasional slightly longer lines. ↩︎ 1.3 Formatting Tools 1.3.1 Clang Many of these BioCro formatting preferences can be applied automatically using the program clang-format with the .clang-format file provided in the base directory of BioCro. Do not apply clang-format to all files indiscriminately, as that will ruin manually-aligned tables. 1.3.1.1 Installation One can install clang-format on Ubunutu using sudo apt install clang-format and on MacOS through Homebrew. 1.3.1.2 Using Clang Files can be formatted using clang-format file_name &gt; new_file or edited in place using clang-format -i file_name If your editor has the ability to display differences between the original and revised versions of the file, it is a good idea to step through and inspect the proposed changes to ensure they are desirable. 1.3.1.3 Clang with the CodeLite IDE On Windows, MacOS, or Linux, the CodeLite IDE includes clang-format and provides an easy way to use it. First go to Plugins -&gt; Source Code Formatter -&gt; Options. In the C++ tab, select use .clang-format file. Now press Ctrl-I or click Plugins -&gt; Source Code Formatter -&gt; Format Current Source to format a file. 1.3.2 EditorConfig Another tool to help with formatting is EditorConfig. EditorConfig, when used in conjunction with the .editorconfig file provided in the base directory of BioCro, provides a method for standardizing settings across different text editors. While some editors have native support, others require a plugin. See the EditorConfig website for more details. "],["generating-documentation.html", "2 Generating Documentation 2.1 Documentation for the C/C++ code. 2.2 Building package vignettes 2.3 Compiling and viewing the bookdown book", " 2 Generating Documentation 2.1 Documentation for the C/C++ code. To generate documentation for the C/C++ code, we use Doxygen. 2.1.1 Required software Doxygen (version 1.9.0 or higher) The Graph visualization toolkit (“GraphViz”; version 2.38 or higher) You can get by without this if you don’t care about generating the dependency graphs. To generate the PDF version of the documentation, a TeX distribution is required. Gnu Make (version 4.3 or higher1) if you want to take advantage of the Makefile recipes Note: None of this is required if you don’t need documentation corresponding to your latest code revisions, and if you are content with one of the four HTML versions of the documentation provided by default. Simply visit https://ebimodeling.github.io/biocro-documentation/ to get documentation of the latest version of the code on the GitHub master branch. 2.1.2 Installation Binary distributions of Doxygen for Linux x86-64, Windows (Vista and later), and for macOS 10.14 and later2 are available on the Doxygen Downloads page. This page also contains information about obtaining a source distribution of Doxygen; a set of instructions for building and installing Doxygen from a source distribution is on the Doxygen Manual’s Installation page. If you use a package manager—APT on Ubuntu or Homebrew on macOS, for example—this is a relatively easy alternative to installing a binary distribution. For example, running sudo apt-get install doxygen graphviz ghostscript on Ubuntu will get you not only Doxygen, but Ghostscript3 and the Graph visualization toolkit as well. (To do something similar on a Mac with Homebrew, run brew install doxygen graphviz ghostscript.) 2.1.3 Generating the Documentation 2.1.3.1 Using the canned Make-file recipes If you have Make installed, the easiest way to generate the Doxygen documentation is to run one of the several recipes in doxygen/Makefile. There are various recipes for generating all of the documentation, only the module documentation or only the framework documentation, for documenting only public members of classes, and for automatically opening a viewer on the just-generated documentation. Run make help in the doxygen directory to see information about all of the available Make targets. 2.1.3.2 Using the doxygen command directly You can build the Doxygen documentation directly, without using Make, by running the command-line command doxygen in the doxygen directory. With no configuration-file argument provided, this will default to using the provided BioCro configuration file doxygen/Doxyfile. 2.1.3.3 Using the Doxygen GUI front-end Doxygen provides a GUI front-end for documentation generation. To use it, simply click (or double-click) on the Doxygen icon. Alternatively, the GUI front-end can be started from the command line by issuing the command doxywizard (in any directory). You can specify a configuration file by passing the file name as the (optional) argument. For example, if you are in BioCro’s doxygen directory, you can do doxywizard Doxyfile to use the default configuration settings for BioCro.4 If you didn’t provide an argument when starting the GUI, or if you started it by clicking its icon, you can select the configuration file from within the GUI program by choosing File/Open… from the application menu (shortcut Ctrl-O, or Cmd-O on Mac) and selecting the desired configuration file in the pop-up file browser. 2.1.3.4 Using your own customizations of the provided Doxyfile If you want to customize your Doxygen builds without having to write a new Doxyfile from scratch, the existing BioCro Doxyfile provides for including a customization file to override the settings in Doxyfile. This works as follows: The doxygen/customizations directory contains a sample customization file named Doxyfile_customization_sample containing some suggestions for customizing your own Doxygen builds. To use this as a template, copy it to a file named Doxyfile (in the same directory) and modify it as you see fit. The settings you set here will override the settings specified in doxygen/Doxyfile. Here are some variables whose settings you might want to consider overriding: INPUT If you are, for example, working on the Doxygen comment for one particular file, you might want to override the value of the INPUT variable so that only the documentation for that one partiuclar file will be generated. This will minimize the generation time and thereby expedite your tweaking the documentation so that appears just as you want it to appear. OUTPUT_DIRECTORY If you are generating your own version of the documentation, you will likely want to override this setting so that existing (complete) documentation is not overwritten. HAVE_DOT Setting this to NO will reduce compilation time vastly, especially if you are compiling from scratch, from something on the order of five or ten minutes to closer to five or ten seconds. So if you don’t care about seeing various diagrams, consider setting HAVE_DOT to NO. Diagrams of various types may be enable or disabled selectively by leaving HAVE_DOT set to YES and using other, more specific settings. For example, you could generate class inheritance diagrams but disable generation of call/caller graphs. See the Doxygen documentation for details, specifically, the section Configuration options related to the dot tool. GENERATE_LATEX If you’re interested in the PDF version of the documentation, you may want to set this to YES. See the sample file for a few other ideas for custom settings. Note: Although this method of customization works with any of make, doxygen, or doxywizard, certain customizations will be ignored when using the Make-file recipes. In particular, customizations of the following variables will be ignored: GENERATE_HTML, GENERATE_TREEVIEW, GENERATE_LATEX, INPUT, OUTPUT_DIRECTORY, EXTRACT_PRIVATE, HTML_COLORSTYLE_HUE. (This may change in the future.) 2.1.4 Viewing and using the documentation Most of the Make-file targets for generating documentation have corresponding targets that both generate the documentation and then automatically open a view of the finished product once generation is complete. Alternatively, you can locate the primary documentation file and manually open the file in the appropriate application (a browser or a PDF-viewer application, as the case may be). For HTML documentation, the file to open is &lt;output_directory&gt;/html/index.html, where &lt;output_directory&gt; is the value of the Doxygen configuration variable OUTPUT_DIRECTORY. (This defaults to the current directory if unset.) For the PDF documentation, the file to open is &lt;output_directory&gt;/latex/refman.pdf. (If you didn’t use one of the Make-file recipes to generate the PDF documentation, you will have to run make in the &lt;output_directory&gt;/latex directory after running Doxygen in order to generate the PDF files from the LaTeX files that Doxygen generates.) A note on using the Doxygen documentation to browse source code The HTML version of the Doxygen documentation provides an alternative to Ctags5 as a convenient way to browse C++ source code: sections documenting classes and functions provide links to the source code where the class or function is defined. Within the source code, names of functions or classes are usually hyper-linked to the file and line where they are defined. 2.2 Building package vignettes 2.2.1 Required software Unless you only want to build vignettes written in Markdown (“.Rmd” files), you will need a TeX installation of some sort. Here are two options: Visit the CTAN starter page and choose and install a TeX distribution designed for your platform. Alternatively, if you mainly want a TeX installation for use in R, you can install the R tinytex package along with some extra needed LaTeX packages not included in TinyTeX by default by proceeding as follows: install.packages(&#39;tinytex&#39;) tinytex::install_tinytex() # Install a few LaTeX packages needed by the vignettes but not # included in tinytex: tinytex::tlmgr_install(c(&#39;siunitx&#39;, &#39;babel-english&#39;, &#39;footnotebackref&#39;, &#39;listings&#39;, &#39;appendix&#39;, &#39;pgf&#39;)) (If you install TeX in this way, you will either need to build the vignettes using one of the Alternative options given below or add TinyTex’s bin directory to your shell path. You can find the root of the TinyTex installation with the R function tinytex::tinytex_root().) If you use the second alternative build option listed below, you will also need the R package devtools: install.packages(&#39;devtools&#39;) 2.2.2 Build procedure The following instructions assume that the root of the BioCro source tree is a directory named biocro. Build the package by running R CMD build biocro from the command line in the directory containing biocro. This includes building the vignettes. Then install using R CMD INSTALL BioCro_xxx.tar.gz, where xxx is the version number. The vignettes should now be available as HTML or PDF files located in path_to_rlib/BioCro/doc, where path_to_rlib is the path to your R library directory. An easy way to pull up an index to the vignettes in a web browser is to run the command browseVignettes('BioCro') in an R session. 2.2.3 Alternative options Here are some alternative methods of building vignettes that don’t require re-installing BioCro. From an R session running in biocro/vignettes, type tools::buildVignette(XXX), where XXX is the name of the particular vignette you wish to build. (It should have extension .Rnw or .Rmd.) The resulting PDF or HTML file will appear in biocro/vignettes. This method is relatively fast and so is especially useful if you are writing a new vignette or revising an existing one. If the vignette being built uses any BioCro code, there must be a version of BioCro installed. From an R session running in any directory of the BioCro source tree, type devtools::build_vignettes(). (Alternatively, start R from anywhere and pass the path to BioCro source tree as the first (“pkg”) argument to build_vignettes().) This method will modify .Rbuildignore and .gitignore, which may be annoying. The resulting HTML and PDF files will appear in the doc directory, which will be created if it doesn’t already exist. This method doesn’t require that BioCro be installed. But it builds and installs BioCro in a temporary location and then builds all the vignettes, and thus it can be somewhat time consuming. Moreover, by default it gives very little indication of build progress, and so it may be useful to override this default and set quiet = FALSE in the function argument list. 2.3 Compiling and viewing the bookdown book Note: A copy of the bookdown BioCro development manual is automatically generated on BioCro’s GitHub documentation site at https://ebimodeling.github.io/biocro-documentation/bookdown_book/index.html. So what follows is likely primarily of interest to developers wishing to revise this book who want to be able to easily view the result of their revisions before committing them. To generate the bookdown BioCro development manual, do as follows: Install Pandoc, if it is not already on your system. See https://pandoc.org/installing.html for instructions. (Note to RStudio users: As mentioned in the R Markdown Cookbook (https://bookdown.org/yihui/rmarkdown-cookbook/install-pandoc.html), RStudio comes with its own copy of Pandoc, so you may be able to get by without installing it separately.) Install the R bookdown package, if it hasn’t been installed already. These instructions are written for bookdown version 0.22 or greater but may work for other versions. In the bookdown directory of your BioCro source tree, run Rscript -e &quot;bookdown::render_book()&quot; Note: If you wish to run render_book from other than the bookdown directory, you may pass a path argument: Rscript -e &quot;bookdown::render_book(&lt;path&gt;) Here, &lt;path&gt; denotes the path from the current directory to the bookdown directory. This only works in bookdown versions 0.22 and later! With earlier versions, you can make use of the xfun::in_dir function: xfun::in_dir(&#39;&lt;path&gt;&#39;, bookdown::render_book()) Again, &lt;path&gt; here denotes the path from the current directory to the bookdown directory. Note: Because some sections of the book are contained in their own files rather than being in a larger file comprising a complete chapter, render_book will issue a warning such as the following, which may be safely ignored: \"In split_chapters(output, gitbook_page, number_sections, split_by, : You have 13 Rmd input file(s) but only 7 first-level heading(s). Did you forget first-level headings in certain Rmd files?\" In a Web browser, open bookdown/_book/index.html. Although versions earlier than 4.3 will probably mostly work, you will get a warning when you use them.↩︎ To launch Doxygen’s GUI front-end on a Mac by clicking on its Application icon, you will need to be using a Mac running macOS version 10.15 or later unless you downgrade your Doxygen installation to version 1.18.20. (Version 10.14 of macOS does support Doxygen 1.9’s doxygen command-line command, however, and it even supports the GUI front-end if it is started from the command-line using the command doxywizard. See Doxygen issue #8334.) Note that if you downgrade, certain reference relations may not be shown in the generated Doxygen documentation (see Doxygen issue #8102). Note also that a bug in version 1.18.19 may render most of the recipes in the provided Make-file (doxygen/Makefile) unusable.↩︎ Ghostscript is used to convert the PostScript files that are generated for formulas in the documentation into bitmaps. But MathJax provides an alternative method of rendering formulas in the HTML documentation, and so Ghostscript is unneeded as long as the Doxygen configuration variable USE_MATHJAX is set to YES. If Ghostscript is used, there may be some compatibility issues between Ghostscript and Doxygen. If you encounter problems, see Doxygen issue #7290 and Doxygen issue #8107 for further information.↩︎ The doxywizard command doesn’t treat Doxyfile as a default configuration file the way the doxygen command does.↩︎ One major advantage of using Ctags over Doxygen for browsing source code is that you can actually make edits to the source code as you are browsing it. If you do use Ctags, a useful option is the flag “–c++-kinds=+p”, which will cause Ctags to create tags for symbols in header files. Emacs users may want to use Etags instead.↩︎ "],["running-the-testthat-tests.html", "3 Running the testthat Tests 3.1 Requirements 3.2 tl;dr 3.3 tl;dr for devtools users 3.4 Continuous integration workflow; why run tests manually? 3.5 Test-running scenarios 3.6 Running individual test files 3.7 Using devtools", " 3 Running the testthat Tests 3.1 Requirements The testthat package. From the R command line, run install.packages('testthat'). 3.2 tl;dr To run all testthat tests, move to the tests directory within the BioCro source code directory tree and run Rscript testthat.R Warning: This assumes the BioCro package has been installed. It will run all tests in the tests/testthat directory against this installed version. If you want the tests to reflect changes to your source code, reinstall BioCro before running them, or use one of the alternative test-running methods outlined below. 3.3 tl;dr for devtools users If you use the devtools package, you can run all tests by doing the following command in any directory in the BioCro source tree: Rscript -e &quot;devtools::test()&quot; This will test against the source code; it does not expect BioCro to be installed. Note that this source code test will compile or recompile the C++ code if necessary. See the source-code testing section (Section 3.5.3) for details. 3.4 Continuous integration workflow; why run tests manually? BioCro’s testthat test suite is automatically run on GitHub as part of the R-CMD-check workflow every time a BioCro developer pushes code to the GitHub master branch. (Users also have the option to trigger this workflow manually by clicking a button on GitHub.) Workflow results are viewable on GitHub under the repository’s Actions tab. There are (at least) two scenarios, however, under which you may want to run tests manually: You have revised the package’s R code, stored data, or C++ code, and you want to run the testthat test suite against the changed code on your own machine before pushing that code to GitHub. You are writing new tests, and you want to ensure that they work as expected. Read on for further information about various topics, including testing package source versus testing an installed package better test reporting options running individual test files 3.5 Test-running scenarios There are two main ways to run the BioCro testthat tests: Run tests in the tests/testthat directory of a BioCro source tree against an installed version of BioCro Run tests in the tests/testthat directory of a BioCro source tree against the code in that source tree (A third scenario exists: running installed testthat tests against the installed package. But currently the BioCro package does not install any of its tests.) 3.5.1 Running the test suite on the installed version of BioCro As explained in the tl;dr section above (Section 3.3), the easiest way to run the tests against an installed version of the BioCro package is to move to the tests directory within the BioCro source code directory tree and run Rscript testthat.R Alternatively, the tests may be run inside an R session as follows: Start an R session (if you don’t have one open already). Run xfun::in_dir('&lt;path to tests directory&gt;', source('testthat.R')), where &lt;path to tests directory&gt; is the path to the tests directory of a BioCro source tree. OR Use setwd to move to the tests directory (if you aren’t there already) and just run source('testthat.R'). Either of these methods will run the testthat tests in the same way that R CMD check would run them. (But R CMD check builds BioCro immediately before running the tests, ensuring that you are running the tests against a version of the BioCro package corresponding to the BioCro code in your source tree.) 3.5.2 Switching reporters The default output of the test method used by testthat.R can be exceedingly terse, and so it is highly desirable to tweak the test output of that method for interactive use. This is done by overriding the default reporter of the testing function using the reporter argument. A particularly useful and informative reporter is the Summary reporter. To use it, run the following commands in an R session: library(BioCro) library(testthat) xfun::in_dir(&#39;&lt;path to tests directory&gt;&#39;, test_check(&#39;BioCro&#39;, reporter = &#39;Summary&#39;)) (If you are in the tests directory, the third line can be simply test_check(&#39;BioCro&#39;, reporter = &#39;Summary&#39;) And if you have already loaded the BioCro and testthat packages (either directly or by sourcing testthat.R), there is no need to reload them!) The Summary reporter is useful in two ways: It clearly indicates testing progress by printing a character to the screen each time a test completes (“.” for success, “S” for a skipped test, “W” for a warning, and an (error) number for a failed test). And it prints the file name of each test file before printing that file’s context message. Setting reporter to ‘Progress’ yields slightly less verbose output. Crucially and inconveniently, it doesn’t print the names of the test files being run, although it does print their context messages. On the other hand, it gives a better numerical summary of the test results—how many tests passed, how many failed, and how many were skipped.6 3.5.3 Running the test suite against the BioCro source code If you are making changes to the R code or to the C++ code (or even to the package data) and you want to test your changes to the source code without installing (or re-installing) the BioCro package, the function to use is test_local.7 The steps are similar to the steps above for running test_check: Start an R session. Load the testthat library: library(testthat). (Note that we don’t need to load the BioCro library, and there needn’t even be a copy of it installed!) Run test_local('&lt;path to the tests directory of some BioCro source tree&gt;') If you are actually in the tests directory—either because you started R there or because you moved there with setwd—you can just run test_local(), because the path defaults to '.'. Note that this function expects to find an up-to-date copy of the BioCro C++ library file (BioCro.so, or BioCro.dll on Windows) in the src directory. If it doesn’t find it (or if it is out of date with respect to the C++ source files), it will try to re-create it. (This will happen even if none of the tests use any of the package code.) So be patient if the function seems to hang for several minutes while it does this! The default reporter for test_local is the Progress reporter, but if you prefer the Summary reporter, which gives better progress indication and prints the name of each test file it runs, you can switch: test_local(&#39;&lt;path to the tests directory of some BioCro source tree&gt;&#39;, reporter = &#39;Summary&#39;)` 3.6 Running individual test files While writing new tests, it is useful to be able to run a single test file rather than the whole test suite. The test may be run either against the installed version of the BioCro package, or against the source code. 3.6.1 Running an individual test file on the installed package Method 1 Start an R session. Load the BioCro and testthat packages: library(BioCro) library(testthat) Call the test_file function on the path to a test file: test_file(&#39;&lt;path to test file to run&gt;&#39;) Note the path passed to test_file can be either a relative or an absolute path. It doesn’t matter what directory the R session was started in or what the current R directory is as long as the path is correct. Making the testthat directory the current directory, however, will make for shorter path names. Once again, the default reporter (“CompactProgress”, in this case) may be overridden: test_file(&#39;&lt;path to test file to run&gt;&#39;, reporter = &#39;Summary&#39;) See the documentation for testthat::Reporter for a list of reporters. Method 2 This uses the test_check function we used earlier (see Section 3.5.2), but with a “filter” option. Start an R session. Load the BioCro and testthat packages: library(BioCro) library(testthat) Call the test_check function with a filter option to select the desired test file. The filter pattern should be a regular expression matching the main part of the test file. For example, to run the tests in test.HarmonicOscillationModeling.R, we could setwd to the tests directory and call test_check as follows: test_check(&#39;BioCro&#39;, filter = &#39;Harm&#39;) The filter matching is performed on file names after they are stripped of “test-” and “.R”. Again, a reporter option may be specified. For example, test_check(&#39;BioCro&#39;, filter = &#39;Harm&#39;, reporter = &#39;Summary&#39;) Note that step 3 assumes you are in the BioCro tests directory when test_check is called. If you aren’t, either usesetwd get there first, or use the xfun::in_dir wrapper: xfun::in_dir(&#39;&lt;path to tests directory&gt;&#39;, test_check(&#39;BioCro&#39;, filter = &#39;Harm&#39;)) 3.6.2 Running an individual test file against the package source code Again, the test_local function is used. The method is exactly the same as specified above in section 3.5.3 except that a filter option is used to limit testing to matching files (see Method 2 in the previous section). 3.7 Using devtools If you don’t mind installing and using the devtools package, it provides a particularly easy way to run tests against the package source code: simply issue the following command in any directory in the BioCro source tree: Rscript -e &quot;devtools::test()&quot; Again, the filter option may be used with this function to limit the tests run, and the default reporter may be overridden with the reporter option. The names “Progress” and “Summary” almost seem to me as if they have been reversed! After all, it is the Summary reporter which most clearly indicates how the testing is progressing and the Progress reporter that gives the best numerical summary of how many tests failed.↩︎ Or you can use devtools::test(). See tl;dr for devtools users and Using devtools.↩︎ "],["adding-the-boost-libraries.html", "4 Adding the Boost libraries 4.1 Why this is needed 4.2 How to extract parts of Boost", " 4 Adding the Boost libraries 4.1 Why this is needed BioCro uses software from the Boost C++ libraries. Boost does not assure backward compatibility, so changes to Boost could break BioCro. Thus, we don’t want to link our code to a user supplied Boost installation, and we include a version with BioCro. Boost is very large, so we want to include only the necessary parts. This document lists steps to extract the relevant parts and update files in BioCro to use them. 4.2 How to extract parts of Boost Use the bcp tool included with Boost to extract parts of the Boost library. bcp accepts a list of files or modules and extracts the relevant parts of the Boost library to a directory. The packages BioCro uses are as follows: Package name Notes boost/units Used in biocro_units.h boost/typeof/incr_registration_group.hpp This is needed for boost/units but it is not exported properly and must be explicitly specificed as of Boost version 1.71 boost/algorithm Used in parameters.h boost/graph Used in dependency_graph.cpp boost/numeric/ublas Used in dynamical_system.h, among others boost/numeric/odeint.hpp Used in Gro.cpp Run the following command: bcp --boost=\"PATH_TO_BOOST_ROOT_DIRECTORY\" \"boost/units\" \"boost/typeof/incr_registration_group.hpp\" \"boost/algorithm\" \"boost/numeric/odeint.hpp\" \"boost/numeric/ublas\" \"boost/graph\" PATH_TO_TEMPORARY_DIRECTORY Copy PATH_TO_TEMPORARY_DIRECTORY/boost to the biocro/boost_[version_number] directory. Other files and directories my be created in PATH_TO_TEMPORARY_DIRECTORY, but they are not needed. If necessary, update the PKG_CPPFLAGS line in biocro/src/Makevars: e.g., PKG_CPPFLAGS=-I\"../boost_1_71_0\" Check that the Boost license at biocro/boost_[version_num] is correct for the version used, and update biocro/LICENSE if necssary. Update the path to the Boost license in biocro/LICENSE. 4.2.1 Notes for using bcp in Windows First, follow the instructions in the “Getting Started on Windows” Boost page. For V1.71.0, this entails the following: - Install the Visual Studio 2019 Developer Command Prompt (see here). - Download the full Boost library, unzip it, and put it somewhere convenient: e.g., C:\\Program Files\\boost\\boost_1_71_0. - Open a VS developer prompt and cd into the boost root directory: e.g., cd C:\\Program Files\\boost\\boost_1_71_0. - Type bootstrap and press enter. This may take a minute or so to complete. - Type .\\b2 and press enter. This may also take a little while. Now the Boost libraries have been built, and we are almost ready to use bcp. However, we need to explicitly build the bcp tool using the “Boost.Build” tool, which is cryptically named “b2.exe”. - In a VS developer prompt, cd into the tools/bcp directory: e.g., cd C:\\Program Files\\boost\\boost_1_71_0\\tools\\bcp. - Run b2.exe using its full path: e.g., type C:\\\"Program Files\"\\boost\\boost_1_71_0\\b2 and press enter. - Now bcp.exe should be in C:\\Program Files\\boost\\boost_1_71_0\\dist\\bin. Finally, cd into the folder that contains bcp: e.g., cd C:\\Program Files\\boost\\boost_1_71_0\\dist\\bin. Now you should be able to run the command listed as “Step 1” above from a VS developer command prompt. "],["the-update-documentation-workflow.html", "5 The Update Documentation Workflow", " 5 The Update Documentation Workflow This workflow, Update Documentation, runs Doxygen in various configurations on the BioCro C++ Library source code and copies and commits the result to the repository given as the value of the “publish-to” environment variable, currently “ebimodeling/biocro-documentation”. That repository is, in turn, set up to publish to a GitHub Pages Web site at the corresponding canonical location (currently, https://ebimodeling.github.io/biocro-documentation/). The workflow runs whenever changes to the C++ source files or the files implementing this workflow are checked into the master branch. It may also be run manually on the GitHub site. In order for this to all work correctly, a number of set-up steps were required: An SSH public/private key pair was generated on a work station using the command ssh-keygen -t rsa -b 4096. (Use the -C option to include a comment. Use an empty pass-phrase) This key pair is used in order to allow a workflow defined in this repository to push files to a different repository (namely, “ebimodeling/biocro-documentation”); see steps 2 and 6 below. The private key was added as a secret in the ebimodeling/biocro repository (this repository) under the key PRIVATE_SSH_KEY. (See https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository. The key name matches the reference secrets.PRIVATE_SSH_KEY used in the document.yml workflow file.) The “ebimodeling/biocro-documentation” repository was created. A README.md file was added to the top-level directory of this new repository with (relative) links pointing to the (prospective) locations of various versions of the Doxygen documentation. GitHub Pages was enabled for the “ebimodeling/biocro-documentation” repository (see https://pages.github.com/). This results in the files in this repository getting automatically published as a Web site to the URL https://ebimodeling.github.io/biocro-documentation/. The public SSH key was added as a deploy key to the “ebimodeling/biocro-documentation” repository under the name “Access from ebimodeling/biocro actions”. (See https://docs.github.com/en/developers/overview/managing-deploy-keys#setup-2. The name “Access from biocro action” is for informational purposes only and has no programmatic significance.) "],["the-doxygen-docker-action-using-makefile-action.html", "6 The Doxygen Docker Action using Makefile Action 6.1 Inputs", " 6 The Doxygen Docker Action using Makefile Action This action is a customization of the code found at https://github.com/mattnotmitt/doxygen-action. Instead of calling Doxygen directly, it assumes that there is a Make file in the working directory that invokes Doxygen to build the documentation. 6.1 Inputs 6.1.1 ‘working-directory’ Required Path of the working directory to change to before running Make. This should be the location of the Make file used with Doxygen. 6.1.2 ‘color’ Optional The color setting (given as an angle from 0 to 360 in the HSL/HSV color space). Default: 143 (greenish) 6.1.3 ‘document-private’ Optional YES to document private class members, NO to document only the public and protected ones. Default: YES 6.1.4 ‘generate-treeview’ Optional YES to generate the Tree View index, NO to omit it. Since the Tree View index takes up screen width, omitting it may facilitate easier browsing of source code. Default: YES 6.1.5 ‘extra-settings’ Optional A space-separated set of settings of the form key=value. Only keys recognized by the make file will have any effect. Example: module_docs_directory=doxygen_docs_modules_public_members_only will change the output directory for module-docs-* targets from doxygen_docs_modules to doxygen_docs_modules_public_members_only. Default: ’’ (blank) 6.1.6 ‘makefile-target’ Optional The name of the Make target to use. Default: ’’ (none) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
